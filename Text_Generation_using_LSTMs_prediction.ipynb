{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation using LSTMs - prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "69XbTFCPT1eY",
        "outputId": "587bfe00-89aa-4967-ef9a-110f345275b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pythainlp==3.0.5 in /usr/local/lib/python3.7/dist-packages (3.0.5)\n",
            "Requirement already satisfied: tinydb>=3.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp==3.0.5) (4.7.0)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp==3.0.5) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp==3.0.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp==3.0.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp==3.0.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp==3.0.5) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from tinydb>=3.0->pythainlp==3.0.5) (3.10.0.2)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 15.4M  100 15.4M    0     0  27.9M      0 --:--:-- --:--:-- --:--:-- 27.9M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 39115  100 39115    0     0   269k      0 --:--:-- --:--:-- --:--:--  269k\n"
          ]
        }
      ],
      "source": [
        "#@title Download and prepare \n",
        "!pip install pythainlp==3.0.5\n",
        "!curl 'https://raw.githubusercontent.com/kokkoks/thai-joke-sentence-generator/main/model.h5' > model.h5\n",
        "!curl 'https://raw.githubusercontent.com/kokkoks/thai-joke-sentence-generator/main/tokenizer.pickle' > tokenizer.pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import numpy as np\n",
        "from pythainlp import word_tokenize\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def generate_text(text, model, max_sequence_len):\n",
        "    seed_text = \" \".join(word_tokenize(text))\n",
        "    counter = 0\n",
        "    while counter < 100:\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = model.predict(token_list, verbose=0)\n",
        "        predicted = np.random.choice(np.arange(0, predicted.shape[1]), p=predicted[0])\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \"+output_word\n",
        "        if output_word == \"END\":\n",
        "          joined_text = \"\".join(seed_text.split(\" \")[:-1])\n",
        "          return joined_text\n",
        "        counter += 1\n",
        "    return seed_text\n",
        "\n",
        "\n",
        "model = tf.keras.models.load_model('model.h5')\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title type initiation sentence \n",
        "\n",
        "text = '\\u0E2D\\u0E22\\u0E32\\u0E01\\u0E01\\u0E34\\u0E19\\u0E41\\u0E0B\\u0E25\\u0E21\\u0E48\\u0E2D\\u0E19\\u0E08\\u0E23\\u0E34\\u0E07\\u0E46\\u0E19\\u0E30' #@param {type:\"string\"}\n",
        "max_sequence_len = 22\n",
        "print(generate_text(text, model, 22))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "P8JxdXTycbLS",
        "outputId": "bf7630ef-6522-4266-d200-01326dbc147b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "อยากกินแซลม่อนจริงๆนะสับรางไวเธอชอบไหม\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_BuXjmaxrXaI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}