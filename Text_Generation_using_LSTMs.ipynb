{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Text Generation using LSTMs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ref: https://www.kaggle.com/shivamb/beginners-guide-to-text-generation-using-lstms"
      ],
      "metadata": {
        "id": "oIww90W1nTTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ref: https://women.trueid.net/detail/kEN97vDvokbn?utm_source=web-trueid&utm_medium=ctw&utm_term=clicklink&utm_campaign=women_4RQeYK5bOmMR_relatecontent_women_kEN97vDvokbn_15/02/2021"
      ],
      "metadata": {
        "id": "I9n9KQ-L5nrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependency"
      ],
      "metadata": {
        "id": "FYGPcjpAB0rC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "!pip install pythainlp==3.0.5"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pythainlp==3.0.5\n",
            "  Downloading pythainlp-3.0.5-py3-none-any.whl (11.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting tinydb>=3.0\n",
            "  Downloading tinydb-4.7.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp==3.0.5) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp==3.0.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp==3.0.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp==3.0.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp==3.0.5) (2021.10.8)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from tinydb>=3.0->pythainlp==3.0.5) (3.10.0.2)\n",
            "Installing collected packages: tinydb, pythainlp\n",
            "Successfully installed pythainlp-3.0.5 tinydb-4.7.0\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEP2dUR-usAA",
        "outputId": "8736cfa3-e5c2-4a58-8caa-4214ea3717cc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1234)\n",
        "from numpy.random import seed\n",
        "# set_random_seed(2)\n",
        "seed(1)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from pythainlp import word_tokenize\n",
        "pd.set_option(\"max_colwidth\", -1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Sg1wUcDnnP4Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "df = pd.read_csv(\"siaw_caption.txt\", names=[\"text\"])"
      ],
      "outputs": [],
      "metadata": {
        "id": "_mDEUzbVtCal"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4955280b-66f9-4aad-bea8-7122846fe716\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>รักของเราอาจไม่หวาน แต่คุณไม่ต้องหารกับใครนะ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ถ้าเธอยังไม่เข้านอน ลองเข้ามาในใจเราก่อนได้นะ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>อยากให้เธอกินคลีนจัง เธอจะได้ลดของมัน แล้วมาเป็นของเรา</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>หลงตัวเองนิดหน่อย แต่ที่หลงบ่อยๆ ก็เธอนั่นแหละ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ชอบตื่นเช้าอ่ะ เพราะไม่อยากรักเธอในวันที่สายเกินไป</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4955280b-66f9-4aad-bea8-7122846fe716')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4955280b-66f9-4aad-bea8-7122846fe716 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4955280b-66f9-4aad-bea8-7122846fe716');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                     text\n",
              "0  รักของเราอาจไม่หวาน แต่คุณไม่ต้องหารกับใครนะ          \n",
              "1  ถ้าเธอยังไม่เข้านอน ลองเข้ามาในใจเราก่อนได้นะ         \n",
              "2  อยากให้เธอกินคลีนจัง เธอจะได้ลดของมัน แล้วมาเป็นของเรา\n",
              "3  หลงตัวเองนิดหน่อย แต่ที่หลงบ่อยๆ ก็เธอนั่นแหละ        \n",
              "4  ชอบตื่นเช้าอ่ะ เพราะไม่อยากรักเธอในวันที่สายเกินไป    "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "metadata": {
        "id": "SN3-o9d5zux_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ac09fffe-2ade-4e94-e161-504d4b4ddc2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize thai sentence"
      ],
      "metadata": {
        "id": "DbOmkpEZCuhq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "df[\"tokens\"] = df[\"text\"].apply(lambda text: word_tokenize(text, keep_whitespace=True))"
      ],
      "outputs": [],
      "metadata": {
        "id": "y97C2EjXuucf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "df[\"processed_tokens\"] = df[\"tokens\"].apply(lambda tokens: tokens + [\"END\"])\n",
        "df[\"processed_sentence\"] = df[\"processed_tokens\"].apply(lambda tokens: \" \".join(tokens))"
      ],
      "outputs": [],
      "metadata": {
        "id": "vmHcveQcu27u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "df[[\"processed_sentence\"]]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-128ea226-48f1-42bb-8347-aba6ccf9476b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>processed_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>รัก ของ เรา อาจ ไม่ หวาน   แต่ คุณ ไม่ต้อง หาร กับ ใคร นะ END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ถ้า เธอ ยัง ไม่ เข้านอน   ลอง เข้ามา ใน ใจ เรา ก่อน ได้ นะ END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>อยาก ให้ เธอ กิน คลี น จัง   เธอ จะ ได้ ลด ของ มัน   แล้ว มา เป็น ของ เรา END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>หลงตัวเอง นิดหน่อย   แต่ ที่ หลง บ่อยๆ   ก็ เธอ นั่นแหละ END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ชอบ ตื่น เช้า อ่ะ   เพราะ ไม่ อยาก รัก เธอ ใน วันที่ สาย เกินไป END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>ใคร มัน จะ อยู่ ข้าง เรา   ได้ดี เท่า เงา ของ ตัวเรา เอง END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>โสด   สวย   สต รอง   ถ้า เธอ ได้ มอง   แล้ วจะ เสียดาย END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>โสด แล้ว ยิ้ม   ดีกว่า ถูก ทิ้ง   แล้ว ร้องไห้ END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>เป็นโสด อย่าง อิสระ   ดีกว่า เข้าไป เป็น ภาระ หัวใจ ใคร END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>อย่า ถาม ว่า ตื่น มา คิดถึง ใคร   ตอบ ได้ ชัดเจน เลย ว่า   ที่นอน END</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-128ea226-48f1-42bb-8347-aba6ccf9476b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-128ea226-48f1-42bb-8347-aba6ccf9476b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-128ea226-48f1-42bb-8347-aba6ccf9476b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                processed_sentence\n",
              "0    รัก ของ เรา อาจ ไม่ หวาน   แต่ คุณ ไม่ต้อง หาร กับ ใคร นะ END                \n",
              "1    ถ้า เธอ ยัง ไม่ เข้านอน   ลอง เข้ามา ใน ใจ เรา ก่อน ได้ นะ END               \n",
              "2    อยาก ให้ เธอ กิน คลี น จัง   เธอ จะ ได้ ลด ของ มัน   แล้ว มา เป็น ของ เรา END\n",
              "3    หลงตัวเอง นิดหน่อย   แต่ ที่ หลง บ่อยๆ   ก็ เธอ นั่นแหละ END                 \n",
              "4    ชอบ ตื่น เช้า อ่ะ   เพราะ ไม่ อยาก รัก เธอ ใน วันที่ สาย เกินไป END          \n",
              "..                                                                   ...          \n",
              "295  ใคร มัน จะ อยู่ ข้าง เรา   ได้ดี เท่า เงา ของ ตัวเรา เอง END                 \n",
              "296  โสด   สวย   สต รอง   ถ้า เธอ ได้ มอง   แล้ วจะ เสียดาย END                   \n",
              "297  โสด แล้ว ยิ้ม   ดีกว่า ถูก ทิ้ง   แล้ว ร้องไห้ END                           \n",
              "298  เป็นโสด อย่าง อิสระ   ดีกว่า เข้าไป เป็น ภาระ หัวใจ ใคร END                  \n",
              "299  อย่า ถาม ว่า ตื่น มา คิดถึง ใคร   ตอบ ได้ ชัดเจน เลย ว่า   ที่นอน END        \n",
              "\n",
              "[300 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "metadata": {
        "id": "U5ojLJBGTi5C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "a6dc7563-89b0-414c-f293-a2d39858a416"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "tokenizer = Tokenizer(lower=False)\n",
        "\n",
        "def get_sequence_of_tokens(corpus):\n",
        "    ## tokenization\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "    \n",
        "    ## convert data to sequence of tokens \n",
        "    input_sequences = []\n",
        "    for line in corpus:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram_sequence = token_list[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "    return input_sequences, total_words\n",
        "\n",
        "inp_sequences, total_words = get_sequence_of_tokens(df[\"processed_sentence\"])"
      ],
      "outputs": [],
      "metadata": {
        "id": "mhQ1g1WwnUun"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "tokenizer.sequences_to_texts(inp_sequences[:10])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['รัก ของ',\n",
              " 'รัก ของ เรา',\n",
              " 'รัก ของ เรา อาจ',\n",
              " 'รัก ของ เรา อาจ ไม่',\n",
              " 'รัก ของ เรา อาจ ไม่ หวาน',\n",
              " 'รัก ของ เรา อาจ ไม่ หวาน แต่',\n",
              " 'รัก ของ เรา อาจ ไม่ หวาน แต่ คุณ',\n",
              " 'รัก ของ เรา อาจ ไม่ หวาน แต่ คุณ ไม่ต้อง',\n",
              " 'รัก ของ เรา อาจ ไม่ หวาน แต่ คุณ ไม่ต้อง หาร',\n",
              " 'รัก ของ เรา อาจ ไม่ หวาน แต่ คุณ ไม่ต้อง หาร กับ']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "metadata": {
        "id": "1i09zRDnuWTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca4364f6-3572-4bba-af64-414b04d8cb30"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "def generate_padded_sequences(input_sequences):\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "    \n",
        "    predictors = input_sequences[:,:-1]\n",
        "    label = input_sequences[:,-1]\n",
        "    label = tf.keras.utils.to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, max_sequence_len\n",
        "\n",
        "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
      ],
      "outputs": [],
      "metadata": {
        "id": "-T_ZXRFcw2ew"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "max_sequence_len"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wrwttN70AO8",
        "outputId": "519334c1-a21d-4d83-9828-8d8227ffa703"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "predictors"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   0,  20],\n",
              "       [  0,   0,   0, ...,   0,  20,  26],\n",
              "       [  0,   0,   0, ...,  20,  26,   4],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   7, 355,  30],\n",
              "       [  0,   0,   0, ..., 355,  30,  24],\n",
              "       [  0,   0,   0, ...,  30,  24, 896]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_vbuk7f0BbS",
        "outputId": "56f96b63-5559-4845-d01f-a067e93e76e7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "total_words"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "897"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tlt--cx40bNb",
        "outputId": "b0b21b8f-e3a0-4262-ab8d-8ab208681fcf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "label.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3577, 897)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcGmno_J0ZOq",
        "outputId": "c9a6e227-400a-47ef-bb30-438f6fd17d00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define structure and train model."
      ],
      "metadata": {
        "id": "WPrQppoMCnUY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "def create_model(max_sequence_len, total_words):\n",
        "    input_len = max_sequence_len - 1\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Embedding(total_words, output_dim=128, input_length=input_len))\n",
        "    \n",
        "    # model.add(LSTM(100))\n",
        "    # model.add(Dropout(0.1))\n",
        "    model.add(LSTM(256, return_sequences=True))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(256, return_sequences=True))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(128))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = create_model(max_sequence_len, total_words)\n",
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 21, 128)           114816    \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 21, 256)           394240    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 21, 256)           0         \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 21, 256)           525312    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 21, 256)           0         \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 128)               197120    \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 897)               115713    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,347,201\n",
            "Trainable params: 1,347,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "id": "eX2CUbQLxPnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0c52b0e-d7e7-4db8-dbc4-a8404f6d704f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
        "\n",
        "model.fit(predictors, label, epochs=500, verbose=1, callbacks=[early_stopping])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "112/112 [==============================] - 10s 32ms/step - loss: 5.8813\n",
            "Epoch 2/500\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 5.5805\n",
            "Epoch 3/500\n",
            "112/112 [==============================] - 4s 31ms/step - loss: 5.5503\n",
            "Epoch 4/500\n",
            "112/112 [==============================] - 4s 32ms/step - loss: 5.5258\n",
            "Epoch 5/500\n",
            "112/112 [==============================] - 3s 31ms/step - loss: 5.4728\n",
            "Epoch 6/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 5.4009\n",
            "Epoch 7/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 5.3571\n",
            "Epoch 8/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 5.2856\n",
            "Epoch 9/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 5.2311\n",
            "Epoch 10/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 5.1604\n",
            "Epoch 11/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 5.0870\n",
            "Epoch 12/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 5.0271\n",
            "Epoch 13/500\n",
            "112/112 [==============================] - 3s 31ms/step - loss: 4.9764\n",
            "Epoch 14/500\n",
            "112/112 [==============================] - 3s 30ms/step - loss: 4.9022\n",
            "Epoch 15/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 4.8334\n",
            "Epoch 16/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 4.7759\n",
            "Epoch 17/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 4.7163\n",
            "Epoch 18/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 4.6483\n",
            "Epoch 19/500\n",
            "112/112 [==============================] - 4s 33ms/step - loss: 4.5747\n",
            "Epoch 20/500\n",
            "112/112 [==============================] - 4s 37ms/step - loss: 4.5361\n",
            "Epoch 21/500\n",
            "112/112 [==============================] - 4s 36ms/step - loss: 4.4748\n",
            "Epoch 22/500\n",
            "112/112 [==============================] - 4s 33ms/step - loss: 4.4081\n",
            "Epoch 23/500\n",
            "112/112 [==============================] - 3s 30ms/step - loss: 4.3660\n",
            "Epoch 24/500\n",
            "112/112 [==============================] - 3s 30ms/step - loss: 4.3063\n",
            "Epoch 25/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 4.2319\n",
            "Epoch 26/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 4.1733\n",
            "Epoch 27/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 4.1161\n",
            "Epoch 28/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 4.0450\n",
            "Epoch 29/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 4.0082\n",
            "Epoch 30/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 3.9324\n",
            "Epoch 31/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 3.8767\n",
            "Epoch 32/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 3.8218\n",
            "Epoch 33/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 3.7598\n",
            "Epoch 34/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 3.6923\n",
            "Epoch 35/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 3.6582\n",
            "Epoch 36/500\n",
            "112/112 [==============================] - 3s 30ms/step - loss: 3.6041\n",
            "Epoch 37/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 3.5623\n",
            "Epoch 38/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 3.5024\n",
            "Epoch 39/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 3.4361\n",
            "Epoch 40/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 3.4019\n",
            "Epoch 41/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 3.3580\n",
            "Epoch 42/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 3.2933\n",
            "Epoch 43/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 3.2411\n",
            "Epoch 44/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 3.2144\n",
            "Epoch 45/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 3.1279\n",
            "Epoch 46/500\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 3.1014\n",
            "Epoch 47/500\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 3.0496\n",
            "Epoch 48/500\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 3.0194\n",
            "Epoch 49/500\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 2.9457\n",
            "Epoch 50/500\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 2.9234\n",
            "Epoch 51/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 2.8755\n",
            "Epoch 52/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 2.8136\n",
            "Epoch 53/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 2.7955\n",
            "Epoch 54/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 2.7565\n",
            "Epoch 55/500\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 2.7167\n",
            "Epoch 56/500\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 2.6731\n",
            "Epoch 57/500\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 2.6443\n",
            "Epoch 58/500\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 2.5913\n",
            "Epoch 59/500\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 2.5329\n",
            "Epoch 60/500\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 2.4935\n",
            "Epoch 61/500\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 2.4815\n",
            "Epoch 62/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 2.4477\n",
            "Epoch 63/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 2.3925\n",
            "Epoch 64/500\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 2.3840\n",
            "Epoch 65/500\n",
            "112/112 [==============================] - 4s 31ms/step - loss: 2.3291\n",
            "Epoch 66/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 2.2963\n",
            "Epoch 67/500\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 2.2567\n",
            "Epoch 68/500\n",
            " 17/112 [===>..........................] - ETA: 2s - loss: 2.1904"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-2391213103ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FuMka01703YN",
        "outputId": "2d9715e2-75a4-48f1-c5fb-efa16cbe0775"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "#     for _ in range(next_words):\n",
        "#         token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "#         token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "#         predicted = model.predict(token_list, verbose=0)\n",
        "#         # predicted = predicted.argmax()\n",
        "#         predicted = np.random.choice(np.arange(0, predicted.shape[1]), p=predicted[0])\n",
        "\n",
        "#         output_word = \"\"\n",
        "#         for word, index in tokenizer.word_index.items():\n",
        "#             if index == predicted:\n",
        "#                 output_word = word\n",
        "#                 break\n",
        "#         seed_text += \" \"+output_word\n",
        "#     return seed_text.title()\n",
        "\n",
        "def generate_text(seed_text, model, max_sequence_len):\n",
        "    counter = 0\n",
        "    while True:\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = model.predict(token_list, verbose=0)\n",
        "        # predicted = predicted.argmax()\n",
        "        predicted = np.random.choice(np.arange(0, predicted.shape[1]), p=predicted[0])\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \"+output_word\n",
        "        if output_word == \"end\" or counter > 100:\n",
        "          return seed_text\n",
        "        counter += 1\n",
        "    return seed_text.title()"
      ],
      "outputs": [],
      "metadata": {
        "id": "fnzYDL5e1Bge"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test_text = \"ของหวาน\"\n",
        "test_input = \" \".join(word_tokenize(test_text))\n",
        "print(generate_text(test_input, model, max_sequence_len))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ของหวาน มี เรียว แต่ เจอ ใน ใจ เรา อยาก กิน เธอ end\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxWk2_yi1gfP",
        "outputId": "460e43f0-b1e1-49a1-d00d-1b715d7052fa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "token_list = tokenizer.texts_to_sequences([test_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "predicted = model.predict(token_list, verbose=0)"
      ],
      "outputs": [],
      "metadata": {
        "id": "G4SmNXXBSrzC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "np.arange(0, predicted.shape[1])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
              "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
              "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
              "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
              "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
              "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
              "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
              "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
              "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
              "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
              "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
              "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
              "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
              "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
              "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
              "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
              "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
              "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
              "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
              "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
              "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
              "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
              "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
              "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
              "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
              "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
              "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
              "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
              "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
              "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
              "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
              "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
              "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
              "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
              "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
              "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
              "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
              "       611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
              "       624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
              "       637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
              "       650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
              "       663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n",
              "       676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n",
              "       689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n",
              "       702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n",
              "       715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n",
              "       728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n",
              "       741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n",
              "       754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766,\n",
              "       767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779,\n",
              "       780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792,\n",
              "       793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n",
              "       806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818,\n",
              "       819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831,\n",
              "       832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n",
              "       845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857,\n",
              "       858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870,\n",
              "       871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883,\n",
              "       884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvNA6DGf8OvI",
        "outputId": "2fcde840-b916-49f7-df97-f1e3e76b2206"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "WsXRyDV38Vlb"
      }
    }
  ]
}